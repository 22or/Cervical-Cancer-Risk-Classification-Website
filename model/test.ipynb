{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3857,"sourceType":"datasetVersion","datasetId":2013}],"dockerImageVersionId":30042,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-25T01:13:14.855487Z","iopub.execute_input":"2021-10-25T01:13:14.855936Z","iopub.status.idle":"2021-10-25T01:13:14.876078Z","shell.execute_reply.started":"2021-10-25T01:13:14.855904Z","shell.execute_reply":"2021-10-25T01:13:14.874909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\n%matplotlib inline\n\nfrom numpy import interp\nfrom scipy.stats import boxcox\n\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom collections import Counter\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import make_pipeline\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.model_selection import cross_validate, StratifiedKFold\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.metrics import f1_score, make_scorer, auc, average_precision_score, precision_score, roc_curve, precision_recall_curve, recall_score, classification_report, confusion_matrix\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:14.87843Z","iopub.execute_input":"2021-10-25T01:13:14.879113Z","iopub.status.idle":"2021-10-25T01:13:15.10458Z","shell.execute_reply.started":"2021-10-25T01:13:14.879067Z","shell.execute_reply":"2021-10-25T01:13:15.103096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check raw data\nraw_data = pd.read_csv(\"/kaggle/input/cervical-cancer-risk-classification/kag_risk_factors_cervical_cancer.csv\")\nraw_data.head(7)\n\n# Find the number of missing entries in each column\ndata_with_null =raw_data.replace('?', np.nan)\ndata_with_null.isnull().sum() \n\n# Remove the two columns with 787 missing entries\nsparsity_removed_data = data_with_null.drop(columns = ['STDs: Time since first diagnosis', 'STDs: Time since last diagnosis'])\nsparsity_removed_data.shape\n\n# Count number of missing entries in each row\nmissing_entries = sparsity_removed_data.isnull().sum(axis=1).tolist()\n\n# Group rows with the same number of missing entries\nnull_mapping = dict((x, missing_entries.count(x)) for x in missing_entries)\nsorted(null_mapping.items())\n\n# Remove all the rows with any null entries\nnull_removed_data = sparsity_removed_data.dropna()\nnull_removed_data.isnull().sum()\n\n# All categorical columns\nobject_cols = [col for col in null_removed_data.columns if null_removed_data[col].dtype == \"object\"]\n\n# Get number of unique entries in each column with categorical data\nobject_nunique = list(map(lambda col: null_removed_data[col].nunique(), object_cols))\nd = dict(zip(object_cols, object_nunique))\n\n# Print number of unique entries by column, in ascending order\nsorted(d.items(), key=lambda x: x[1])\n\n# Convert all categorical columns to float data\ncolumn_new_dtypes = {key: 'float64' for key in d}\ndf = null_removed_data.astype(column_new_dtypes)\ndf.info()\n\n#df = null_removed_data.apply(pd.to_numeric)\n#df.info()\n\n# Get details of the null removed data, i.e., Mean, Min, Max etc\ndf.describe()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-10-25T01:13:15.106254Z","iopub.execute_input":"2021-10-25T01:13:15.106915Z","iopub.status.idle":"2021-10-25T01:13:15.330926Z","shell.execute_reply.started":"2021-10-25T01:13:15.106873Z","shell.execute_reply":"2021-10-25T01:13:15.329203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print number of unique entries by column, in ascending order\nsorted(d.items(), key=lambda x: x[1])","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:15.334737Z","iopub.execute_input":"2021-10-25T01:13:15.335455Z","iopub.status.idle":"2021-10-25T01:13:15.344932Z","shell.execute_reply.started":"2021-10-25T01:13:15.335414Z","shell.execute_reply":"2021-10-25T01:13:15.343326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation Matrix for each features\ncorrmat = round(df.corr(), 2)\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\n#plot heat map\ng=sns.heatmap(df[top_corr_features].corr(),annot=True,fmt='.2f',cmap=\"YlGnBu\")","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:15.351073Z","iopub.execute_input":"2021-10-25T01:13:15.351797Z","iopub.status.idle":"2021-10-25T01:13:20.032806Z","shell.execute_reply.started":"2021-10-25T01:13:15.351648Z","shell.execute_reply":"2021-10-25T01:13:20.031575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BoxPlot showing raw distribution of features\nplt.figure(figsize=(16,4))\ndf.iloc[:,:].boxplot()\nplt.title('(Raw) Distribution of Features', fontsize=17)\n# Get current axes\nax = plt.gca()\n# Make space for and rotate the x-axis tick labels\nplt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:20.034425Z","iopub.execute_input":"2021-10-25T01:13:20.034874Z","iopub.status.idle":"2021-10-25T01:13:20.761912Z","shell.execute_reply.started":"2021-10-25T01:13:20.034831Z","shell.execute_reply":"2021-10-25T01:13:20.760772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.mode()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:20.763597Z","iopub.execute_input":"2021-10-25T01:13:20.764304Z","iopub.status.idle":"2021-10-25T01:13:20.809819Z","shell.execute_reply.started":"2021-10-25T01:13:20.764235Z","shell.execute_reply":"2021-10-25T01:13:20.808598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.median()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:20.812135Z","iopub.execute_input":"2021-10-25T01:13:20.812636Z","iopub.status.idle":"2021-10-25T01:13:20.828246Z","shell.execute_reply.started":"2021-10-25T01:13:20.812592Z","shell.execute_reply":"2021-10-25T01:13:20.826865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove outliers\ndf.drop(df.index[df['Age'] > 52], inplace = True)\ndf.drop(df.index[df['Number of sexual partners'] > 8], inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:20.830495Z","iopub.execute_input":"2021-10-25T01:13:20.83172Z","iopub.status.idle":"2021-10-25T01:13:20.843753Z","shell.execute_reply.started":"2021-10-25T01:13:20.831671Z","shell.execute_reply":"2021-10-25T01:13:20.842239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define target variables and remove target columns from data\ny1 = df.Hinselmann\ny2 = df.Schiller\ny3 = df.Citology\ny4 = df.Biopsy\nX = df.drop(['Hinselmann', 'Schiller', 'Citology', 'Biopsy'], axis=1)\n\n# Count number of class 1 and class 0 samples for each target\nprint('_' * 30)\nprint(\"Capturing Class Imbalance\")\nprint(y1.value_counts())\nprint(y2.value_counts())\nprint(y3.value_counts())\nprint(y4.value_counts())\n\nt1 = sparsity_removed_data.Hinselmann\nt2 = sparsity_removed_data.Schiller\nt3 = sparsity_removed_data.Citology\nt4 = sparsity_removed_data.Biopsy\n\n# Count number of class 1 and class 0 samples for each target\nprint('_' * 30)\nprint(\"Data with null values:\")\nprint(t1.value_counts())\nprint(t2.value_counts())\nprint(t3.value_counts())\nprint(t4.value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:20.846065Z","iopub.execute_input":"2021-10-25T01:13:20.846893Z","iopub.status.idle":"2021-10-25T01:13:20.878971Z","shell.execute_reply.started":"2021-10-25T01:13:20.846846Z","shell.execute_reply":"2021-10-25T01:13:20.876464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert age to Age groups - Min age: 13, Max age: 52\n# 10 to 14 --> Group 1\n# 15 to 19 --> Group 2\n# ...\n# 50 to 54 --> Group 9\n\nage_bins = np.arange(9, 55 , 5)\nage_labels = np.arange(1, 10)\nX['age_group'] = pd.cut(X.Age, bins = age_bins, labels = age_labels)\nX['age_group'] =  pd.to_numeric(X['age_group'])\n\n# df[['Age','age_group']].head(20)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:20.880433Z","iopub.execute_input":"2021-10-25T01:13:20.881044Z","iopub.status.idle":"2021-10-25T01:13:20.895677Z","shell.execute_reply.started":"2021-10-25T01:13:20.880982Z","shell.execute_reply":"2021-10-25T01:13:20.894011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Similarly convert first sexual intercourse age, Min age: 10, Max age: 32\nfsi_bins = np.arange(9, 35 , 5)\nfsi_labels = np.arange(1, 6)\nX['fsi_group'] = pd.cut(X['First sexual intercourse'], bins = fsi_bins, labels = fsi_labels)\nX['fsi_group'] =  pd.to_numeric(X['fsi_group'])\n\n# df[['Age', 'First sexual intercourse', 'fsi_group']].head(20)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:20.898548Z","iopub.execute_input":"2021-10-25T01:13:20.898921Z","iopub.status.idle":"2021-10-25T01:13:20.912461Z","shell.execute_reply.started":"2021-10-25T01:13:20.898892Z","shell.execute_reply":"2021-10-25T01:13:20.911236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop Age, First Sexual Intercourse columns\nX = X.drop(columns=['Age', 'First sexual intercourse'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:20.914743Z","iopub.execute_input":"2021-10-25T01:13:20.915433Z","iopub.status.idle":"2021-10-25T01:13:20.922761Z","shell.execute_reply.started":"2021-10-25T01:13:20.91539Z","shell.execute_reply":"2021-10-25T01:13:20.921277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.nunique(axis=0).sort_values()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:20.924914Z","iopub.execute_input":"2021-10-25T01:13:20.925784Z","iopub.status.idle":"2021-10-25T01:13:20.946047Z","shell.execute_reply.started":"2021-10-25T01:13:20.925742Z","shell.execute_reply":"2021-10-25T01:13:20.944699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove columns with only one unique value\nX = X.drop(['STDs:cervical condylomatosis', 'STDs:AIDS'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:20.947893Z","iopub.execute_input":"2021-10-25T01:13:20.948603Z","iopub.status.idle":"2021-10-25T01:13:20.956218Z","shell.execute_reply.started":"2021-10-25T01:13:20.94856Z","shell.execute_reply":"2021-10-25T01:13:20.954857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sns.relplot(x=\"Number of sexual partners\", y=y1.name, data=df);","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:20.957775Z","iopub.execute_input":"2021-10-25T01:13:20.958566Z","iopub.status.idle":"2021-10-25T01:13:20.967346Z","shell.execute_reply.started":"2021-10-25T01:13:20.958494Z","shell.execute_reply":"2021-10-25T01:13:20.966038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_classif\n\n\"\"\"def make_mi_scores(X, y):\n    mi_scores = mutual_info_classif(X, y)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\nmi_scores = make_mi_scores(X, y1)\npositive_mi = mi_scores[mi_scores != 0]\npositive_mi\n\n\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:20.968903Z","iopub.execute_input":"2021-10-25T01:13:20.969701Z","iopub.status.idle":"2021-10-25T01:13:20.979212Z","shell.execute_reply.started":"2021-10-25T01:13:20.969653Z","shell.execute_reply":"2021-10-25T01:13:20.977538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"def plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")\n\n\nplt.figure(dpi=100, figsize=(8, 5))\nplot_mi_scores(positive_mi)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:20.981252Z","iopub.execute_input":"2021-10-25T01:13:20.982089Z","iopub.status.idle":"2021-10-25T01:13:20.991015Z","shell.execute_reply.started":"2021-10-25T01:13:20.982041Z","shell.execute_reply":"2021-10-25T01:13:20.989463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"norm_columns = ['Age', 'Number of sexual partners', 'First sexual intercourse', \n                'Num of pregnancies', 'Smokes (years)', 'Smokes (packs/year)', \n               'Hormonal Contraceptives (years)', 'IUD (years)', 'STDs (number)',\n               'STDs: Number of diagnosis']\n\nX.hist(figsize=(15,15))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:20.998468Z","iopub.execute_input":"2021-10-25T01:13:20.998785Z","iopub.status.idle":"2021-10-25T01:13:21.00596Z","shell.execute_reply.started":"2021-10-25T01:13:20.998757Z","shell.execute_reply":"2021-10-25T01:13:21.004642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalise Age\n\"\"\"X['Age Norm'] = boxcox(X['Age'], 0.5)\nX.hist('Age Norm')\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:21.008328Z","iopub.execute_input":"2021-10-25T01:13:21.00916Z","iopub.status.idle":"2021-10-25T01:13:21.017547Z","shell.execute_reply.started":"2021-10-25T01:13:21.009113Z","shell.execute_reply":"2021-10-25T01:13:21.015601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.special import boxcox1p\n\n# Normalise Age\n\"\"\"X['Num of pregnancies (Norm)'] = boxcox1p(X['Num of pregnancies'], 0.7)\nX.hist('Num of pregnancies (Norm)')\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:21.019612Z","iopub.execute_input":"2021-10-25T01:13:21.020502Z","iopub.status.idle":"2021-10-25T01:13:21.029217Z","shell.execute_reply.started":"2021-10-25T01:13:21.020427Z","shell.execute_reply":"2021-10-25T01:13:21.027749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First regularize data b/w 1 and 2\nscaler = MinMaxScaler(feature_range=(1, 2))\n\n# Use PowerTransformer to normalize data\npower = PowerTransformer(method='box-cox')\npipeline = Pipeline(steps=[('s', scaler),('p', power)])\nXnorm = pipeline.fit_transform(X)\n\nXnorm = pd.DataFrame(Xnorm)\nXnorm.hist(figsize=(15,15))\n#result_df = df1.apply(lambda col: stats.boxcox(col, a.loc[col.name]))","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:21.031217Z","iopub.execute_input":"2021-10-25T01:13:21.032156Z","iopub.status.idle":"2021-10-25T01:13:25.425373Z","shell.execute_reply.started":"2021-10-25T01:13:21.032109Z","shell.execute_reply":"2021-10-25T01:13:25.424166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xnorm.columns = X.columns","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:25.427415Z","iopub.execute_input":"2021-10-25T01:13:25.428151Z","iopub.status.idle":"2021-10-25T01:13:25.433985Z","shell.execute_reply.started":"2021-10-25T01:13:25.428104Z","shell.execute_reply":"2021-10-25T01:13:25.43264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_columns = X.columns.tolist()\nX_columns","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:25.435921Z","iopub.execute_input":"2021-10-25T01:13:25.436754Z","iopub.status.idle":"2021-10-25T01:13:25.448855Z","shell.execute_reply.started":"2021-10-25T01:13:25.436709Z","shell.execute_reply":"2021-10-25T01:13:25.447481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"#feat_name = 'STDs:condylomatosis'\nfor ft_name in X_columns:\n\n    # Frequency distribution of Age\n    print(X.groupby([ft_name]).size())\n    \n    for tes in [y1.name, y2.name, y3.name, y4.name]:\n        print(tes)\n        hins_age = df.loc[df[tes] == 1]\n        print(hins_age.groupby([ft_name]).size())\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:25.452464Z","iopub.execute_input":"2021-10-25T01:13:25.452939Z","iopub.status.idle":"2021-10-25T01:13:25.462441Z","shell.execute_reply.started":"2021-10-25T01:13:25.452906Z","shell.execute_reply":"2021-10-25T01:13:25.461034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"for tes in [y1.name, y2.name, y3.name, y4.name]:\n    print(tes)\n    hins_age = df.loc[df[tes] == 1]\n    hins_age.groupby([feat_name]).size()\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:25.464329Z","iopub.execute_input":"2021-10-25T01:13:25.465274Z","iopub.status.idle":"2021-10-25T01:13:25.473174Z","shell.execute_reply.started":"2021-10-25T01:13:25.465232Z","shell.execute_reply":"2021-10-25T01:13:25.471825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BoxPlot showing raw distribution of features\nplt.figure(figsize=(16,4))\nX.iloc[:,:].boxplot()\nplt.title('(Raw) Distribution of Features - Transformed', fontsize=17)\n# Get current axes\nax = plt.gca()\n# Make space for and rotate the x-axis tick labels\nplt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:25.475239Z","iopub.execute_input":"2021-10-25T01:13:25.476181Z","iopub.status.idle":"2021-10-25T01:13:26.092609Z","shell.execute_reply.started":"2021-10-25T01:13:25.476137Z","shell.execute_reply":"2021-10-25T01:13:26.091548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One of the most important step while working with highly imbalanced dataset is to balance the classes. There are several tecniques which provide a mechanism for balancing the dataset. These involve Random undersampling of the majority class, Oversampling of the minority class, Cluster based Oversampling and Synthetic Minority Oversampling Technique (SMOTE). Here we will use SMOTE.","metadata":{}},{"cell_type":"code","source":"# Balance Classes\n# Join the train data\ntrain1 = Xnorm.join(y1)\ntrain2 = Xnorm.join(y2)\ntrain3 = Xnorm.join(y3)\ntrain4 = Xnorm.join(y4)\n\n#print('Data (Hinselmann) shape before balancing:',len(train1))\nprint('\\nCounts of positive VS negative (Hinselmann) in original data:')\nprint(train1.Hinselmann.value_counts())\nprint('-'*40)\n\n#print('Data (Schiller) shape before balancing:',train2.shape)\nprint('\\nCounts of positive VS negative (Schiller) in original data:')\nprint(train2.Schiller.value_counts())\nprint('-'*40)\n\n#print('Data (Citology) shape before balancing:',train3.shape)\nprint('\\nCounts of positive VS negative (Citology) in original data:')\nprint(train3.Citology.value_counts())\nprint('-'*40)\n\n#print('Data (Biopsy) shape before balancing:',train4.shape)\nprint('\\nCounts of positive VS negative (Biopsy) in original data:')\nprint(train4.Biopsy.value_counts())\nprint('-'*40)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:26.094999Z","iopub.execute_input":"2021-10-25T01:13:26.095419Z","iopub.status.idle":"2021-10-25T01:13:26.13128Z","shell.execute_reply.started":"2021-10-25T01:13:26.095379Z","shell.execute_reply":"2021-10-25T01:13:26.130307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y1.name","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:26.132724Z","iopub.execute_input":"2021-10-25T01:13:26.133178Z","iopub.status.idle":"2021-10-25T01:13:26.140441Z","shell.execute_reply.started":"2021-10-25T01:13:26.133137Z","shell.execute_reply":"2021-10-25T01:13:26.139012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Oversample positives. Imblearn's ADASYN was built for class-imbalanced datasets\nX1_bal, y1_bal = ADASYN(sampling_strategy='minority',random_state=0).fit_resample(\n    Xnorm,\n    y1)\n\n# Oversample positives. Imblearn's ADASYN was built for class-imbalanced datasets\nX2_bal, y2_bal = ADASYN(sampling_strategy='minority',random_state=0).fit_resample(\n    Xnorm,\n    y2)\n\n# Oversample positives. Imblearn's ADASYN was built for class-imbalanced datasets\nX3_bal, y3_bal = ADASYN(sampling_strategy='minority',random_state=0).fit_resample(\n    Xnorm,\n    y3)\n\n# Oversample positives. Imblearn's ADASYN was built for class-imbalanced datasets\nX4_bal, y4_bal = ADASYN(sampling_strategy='minority',random_state=0).fit_resample(\n    Xnorm,\n    y4)\n\n# Join X and y\nX1_bal = pd.DataFrame(X1_bal,columns=Xnorm.columns)\ny1_bal = pd.DataFrame(y1_bal,columns=['Hinselmann'])\nbalanced1 = X1_bal.join(y1_bal)\n\n# Join X and y\nX2_bal = pd.DataFrame(X2_bal,columns=Xnorm.columns)\ny2_bal = pd.DataFrame(y2_bal,columns=['Schiller'])\nbalanced2 = X2_bal.join(y2_bal)\n\n# Join X and y\nX3_bal = pd.DataFrame(X3_bal,columns=Xnorm.columns)\ny3_bal = pd.DataFrame(y3_bal,columns=['Citology'])\nbalanced3 = X3_bal.join(y3_bal)\n\n# Join X and y\nX4_bal = pd.DataFrame(X4_bal,columns=Xnorm.columns)\ny4_bal = pd.DataFrame(y4_bal,columns=['Biopsy'])\nbalanced4 = X4_bal.join(y4_bal)\n\n\nprint('-'*40)\nprint('Data (Hinselmann) shape after balancing:',balanced1.shape)\nprint('\\nCounts of positive VS negative in new data:')\nprint(balanced1.Hinselmann.value_counts())\n\nprint('-'*40)\nprint('Data (Schiller) shape after balancing:',balanced2.shape)\nprint('\\nCounts of positive VS negative in new data:')\nprint(balanced2.Schiller.value_counts())\n\nprint('-'*40)\nprint('Data (Citology) shape after balancing:',balanced3.shape)\nprint('\\nCounts of positive VS negative in new data:')\nprint(balanced3.Citology.value_counts())\n\nprint('-'*40)\nprint('Data (Biopsy) shape after balancing:',balanced4.shape)\nprint('\\nCounts of positive VS negative in new data:')\nprint(balanced4.Biopsy.value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:26.141977Z","iopub.execute_input":"2021-10-25T01:13:26.142451Z","iopub.status.idle":"2021-10-25T01:13:26.251296Z","shell.execute_reply.started":"2021-10-25T01:13:26.142409Z","shell.execute_reply":"2021-10-25T01:13:26.248344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y1_bal.columns.name = 'Hinselmann'\ny2_bal.columns.name = 'Schiller'\ny3_bal.columns.name = 'Citology'\ny4_bal.columns.name = 'Biopsy'\n\ntargets = [y1_bal.columns.name, y2_bal.columns.name, y3_bal.columns.name, y4_bal.columns.name]","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:26.256738Z","iopub.execute_input":"2021-10-25T01:13:26.257048Z","iopub.status.idle":"2021-10-25T01:13:26.26513Z","shell.execute_reply.started":"2021-10-25T01:13:26.257001Z","shell.execute_reply":"2021-10-25T01:13:26.26374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef draw_cv_roc_curve(classifier, cv, X, y, title='ROC Curve'):\n    \"\"\"\n    Draw a Cross Validated ROC Curve.\n    Keyword Args:\n        classifier: Classifier Object\n        cv: StratifiedKFold Object\n        X: Feature Pandas DataFrame\n        y: Response Pandas Series\n    Example largely taken from http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py\n    \"\"\"\n    # Creating ROC Curve with Cross Validation\n    tprs = []\n    aucs = []\n    mean_fpr = np.linspace(0, 1, 100)\n    mean_auc = 0\n    std_auc = 0\n\n    i = 0\n    for train, test in cv.split(X, y):\n        \n        probas_ = classifier.fit(X.iloc[train], y.iloc[train]).predict_proba(X.iloc[test])\n        # Compute ROC curve and area the curve\n        fpr, tpr, thresholds = roc_curve(y.iloc[test], probas_[:, 1])\n        tprs.append(interp(mean_fpr, fpr, tpr))\n\n        tprs[-1][0] = 0.0\n        roc_auc = auc(fpr, tpr)\n        aucs.append(roc_auc)\n        plt.plot(fpr, tpr, lw=1, alpha=0.3,\n                 label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n\n        i += 1\n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n             label='Luck', alpha=.8)\n\n    mean_tpr = np.mean(tprs, axis=0)\n    mean_tpr[-1] = 1.0\n    mean_auc = auc(mean_fpr, mean_tpr)\n    std_auc = np.std(aucs)\n    plt.plot(mean_fpr, mean_tpr, color='b',\n             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n             lw=2, alpha=.8)\n\n    std_tpr = np.std(tprs, axis=0)\n    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n                     label=r'$\\pm$ 1 std. dev.')\n\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(title)\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    return mean_auc\n","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:26.266614Z","iopub.execute_input":"2021-10-25T01:13:26.2671Z","iopub.status.idle":"2021-10-25T01:13:26.290817Z","shell.execute_reply.started":"2021-10-25T01:13:26.267063Z","shell.execute_reply":"2021-10-25T01:13:26.288783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_cv_pr_curve(classifier, cv, X, y, title='PR Curve'):\n    \"\"\"\n    Draw a Cross Validated PR Curve.\n    Keyword Args:\n        classifier: Classifier Object\n        cv: StratifiedKFold Object: (https://stats.stackexchange.com/questions/49540/understanding-stratified-cross-validation)\n        X: Feature Pandas DataFrame\n        y: Response Pandas Series\n\n    Largely taken from: https://stackoverflow.com/questions/29656550/how-to-plot-pr-curve-over-10-folds-of-cross-validation-in-scikit-learn\n    \"\"\"\n    y_real = []\n    y_proba = []\n\n    i = 0\n    for train, test in cv.split(X, y):\n        trainer = classifier.fit(X.iloc[train], y.iloc[train])\n        probas_ = trainer.predict_proba(X.iloc[test])\n        \n        #plot_importance(xgbc)\n        #print(get_feature_importance(trainer))\n        \n        # Compute ROC curve and area the curve\n        precision, recall, _ = precision_recall_curve(y.iloc[test], probas_[:, 1])\n        \n        # Plotting each individual PR Curve\n        plt.plot(recall, precision, lw=1, alpha=0.3,\n                 label='PR fold %d (AUC = %0.2f)' % (i, average_precision_score(y.iloc[test], probas_[:, 1])))\n\n        y_real.append(y.iloc[test])\n        y_proba.append(probas_[:, 1])\n\n        i += 1\n\n    y_real = np.concatenate(y_real)\n    y_proba = np.concatenate(y_proba)\n\n    precision, recall, _ = precision_recall_curve(y_real, y_proba)\n\n    pr_auc = average_precision_score(y_real, y_proba)\n    plt.plot(recall, precision, color='b',\n             label=r'Precision-Recall (AUC = %0.2f)' % (pr_auc),\n             lw=2, alpha=.8)\n\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title(title)\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    return pr_auc","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:26.292714Z","iopub.execute_input":"2021-10-25T01:13:26.293415Z","iopub.status.idle":"2021-10-25T01:13:26.312222Z","shell.execute_reply.started":"2021-10-25T01:13:26.293371Z","shell.execute_reply":"2021-10-25T01:13:26.311088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting up simple RF Classifier\nrfc = RandomForestClassifier(random_state=42)\n\nxgbc = XGBClassifier(n_estimators=10, \n                     max_depth=5, \n                     learning_rate=0.4, \n                     random_state=42)\n\nsvc = Pipeline([ (\"pre\", preprocessing.StandardScaler()), \n                    (\"classifier\", SVC(C=1, \n                                       probability=True, random_state=42))])\n\nknn = KNeighborsClassifier()\n\nclfs = [svc, rfc, knn, xgbc]","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:26.315175Z","iopub.execute_input":"2021-10-25T01:13:26.316032Z","iopub.status.idle":"2021-10-25T01:13:26.334335Z","shell.execute_reply.started":"2021-10-25T01:13:26.315976Z","shell.execute_reply":"2021-10-25T01:13:26.333017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cvs = []\nfor split_value in [4, 5, 6, 7, 8, 9]:\n    # Set up Stratified K Fold\n    cvs.append(StratifiedKFold(n_splits=split_value, random_state=0))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:26.338039Z","iopub.execute_input":"2021-10-25T01:13:26.338401Z","iopub.status.idle":"2021-10-25T01:13:26.350611Z","shell.execute_reply.started":"2021-10-25T01:13:26.338371Z","shell.execute_reply":"2021-10-25T01:13:26.349242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cvs[1].n_splits","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:26.353219Z","iopub.execute_input":"2021-10-25T01:13:26.354745Z","iopub.status.idle":"2021-10-25T01:13:26.366378Z","shell.execute_reply.started":"2021-10-25T01:13:26.354696Z","shell.execute_reply":"2021-10-25T01:13:26.364699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_classifier_name(clf):\n    cn = clf.__class__.__name__\n    class_name = cn if (cn != 'Pipeline') else 'SVC'\n    return class_name","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:26.370848Z","iopub.execute_input":"2021-10-25T01:13:26.371163Z","iopub.status.idle":"2021-10-25T01:13:26.377542Z","shell.execute_reply.started":"2021-10-25T01:13:26.371132Z","shell.execute_reply":"2021-10-25T01:13:26.376155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oversampled_data = [(X1_bal, y1_bal), (X2_bal, y2_bal), (X3_bal, y3_bal), (X4_bal, y4_bal)]\nmean_scores_roc = {}\nfor clf in clfs:\n    for cv in cvs:\n        clf_name = get_classifier_name(clf)\n        key = clf_name+str(cv.n_splits)\n        #Add new keys with classifier name in the dictionary\n        mean_scores_roc[key] = []\n        print('_'*30,'\\n\\n',clf_name,'\\n', '_'*30)\n        for X_bal,target in oversampled_data:\n            roc_title = str(cv.n_splits) + '-fold Cross Validated ROC curve for ' + target.columns.name + ' - ' + clf_name\n            mean_scores_roc[key].append(draw_cv_roc_curve(clf, cv, X_bal, target, title=roc_title))","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:13:26.379254Z","iopub.execute_input":"2021-10-25T01:13:26.379966Z","iopub.status.idle":"2021-10-25T01:15:33.61401Z","shell.execute_reply.started":"2021-10-25T01:13:26.379892Z","shell.execute_reply":"2021-10-25T01:15:33.612765Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_scores_pr = {}\nfor clf in clfs:\n    \n    for cv in cvs:\n        clf_name = get_classifier_name(clf)\n        key = clf_name+str(cv.n_splits)\n        \n        mean_scores_pr[key] = []\n        print('_'*30,'\\n\\n',clf_name,'\\n', '_'*30)\n        for X_bal,target in oversampled_data:\n            pr_title = str(cv.n_splits) + '-fold Cross Validated PR Curve for ' + target.columns.name + ' - ' + clf_name\n            mean_scores_pr[key].append(draw_cv_pr_curve(clf, cv, X_bal, target, title=pr_title))","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:15:33.615833Z","iopub.execute_input":"2021-10-25T01:15:33.616515Z","iopub.status.idle":"2021-10-25T01:17:36.428094Z","shell.execute_reply.started":"2021-10-25T01:15:33.616464Z","shell.execute_reply":"2021-10-25T01:17:36.426726Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataFrame to store classifier performance\nperformance_roc = pd.DataFrame(columns=targets)\nfor clf in clfs:\n    for cv in cvs:\n        key = get_classifier_name(clf)+str(cv.n_splits)\n        performance_roc.loc[key,\n                            targets] = mean_scores_roc[key]\nprint('_'*50,'\\n\\n', 'Table depicting ROC AUC scores', '\\n', '_'*50)\n    \nperformance_roc","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:17:36.429774Z","iopub.execute_input":"2021-10-25T01:17:36.430439Z","iopub.status.idle":"2021-10-25T01:17:36.481613Z","shell.execute_reply.started":"2021-10-25T01:17:36.430397Z","shell.execute_reply":"2021-10-25T01:17:36.480161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataFrame to store classifier performance\nperformance_roc = pd.DataFrame(columns=targets)\nfor clf in clfs:\n    for cv in cvs:\n        key = get_classifier_name(clf)+str(cv.n_splits)\n        performance_roc.loc[key,\n                            targets] = mean_scores_roc[key]\nprint('_'*50,'\\n\\n', 'Table depicting ROC AUC scores', '\\n', '_'*50)\n    \nperformance_roc","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:17:36.483231Z","iopub.execute_input":"2021-10-25T01:17:36.483862Z","iopub.status.idle":"2021-10-25T01:17:36.545914Z","shell.execute_reply.started":"2021-10-25T01:17:36.483818Z","shell.execute_reply":"2021-10-25T01:17:36.544921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataFrame to store classifier performance\nperformance_pr = pd.DataFrame(columns=targets)\n\nfor clf in clfs:\n    for cv in cvs:\n        key = get_classifier_name(clf)+str(cv.n_splits)\n        performance_pr.loc[key,\n                            targets] = mean_scores_pr[key]\nprint('_'*50,'\\n\\n', 'Table depicting Precision-Recall AUC scores', '\\n', '_'*50)\n    \nperformance_pr","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:17:36.549472Z","iopub.execute_input":"2021-10-25T01:17:36.549911Z","iopub.status.idle":"2021-10-25T01:17:36.601952Z","shell.execute_reply.started":"2021-10-25T01:17:36.54987Z","shell.execute_reply":"2021-10-25T01:17:36.600164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\nfrom IPython.display import display\n\n# Get feature names to be displayed\nfeat_names = X1_bal.columns.tolist()\n\n# Select each classifier one by one\nfor clf in clfs:\n    \n    print('_'*40,'\\n',get_classifier_name(clf),'\\n', '_'*40)\n    # PermutationImportance object for each classifier\n    permuter = PermutationImportance(clf, scoring='roc_auc', cv='prefit', random_state=42)\n    \n    # Calculate feature importance for all 4 target variables\n    for X_bal,y_bal in oversampled_data:\n        permuter.fit(X_bal, y_bal)\n        print('_'*40,'\\n\\n','Feature Importance (', y_bal.columns.name, ') - ', get_classifier_name(clf), '\\n', '_'*40,'\\n')\n        display(eli5.show_weights(permuter, feature_names = feat_names))","metadata":{"execution":{"iopub.status.busy":"2021-10-25T01:17:36.603737Z","iopub.execute_input":"2021-10-25T01:17:36.60421Z","iopub.status.idle":"2021-10-25T01:19:08.145613Z","shell.execute_reply.started":"2021-10-25T01:17:36.604178Z","shell.execute_reply":"2021-10-25T01:19:08.143397Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}